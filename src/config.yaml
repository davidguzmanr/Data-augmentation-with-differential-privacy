# pytorch_lightning==1.7.7
seed_everything: 42
trainer:
  accelerator: auto
  devices: 1
  max_epochs: 50
  logger: true
  enable_checkpointing: true
  enable_progress_bar: true
  log_every_n_steps: 32
  precision: 32
  enable_model_summary: true
  callbacks:
    - class_path: pytorch_lightning.callbacks.LearningRateMonitor
      init_args:
        logging_interval: epoch
        log_momentum: false 
model:
  epochs: 50
  batch_size: 128
  lr: 0.01
  weight_decay: 5e-3
  optimizer_name: SGD
  differential_privacy: false
  data_augmentation: false
  epsilon: 10.0
  delta: 1e-5
  max_grad_norm: 1.2
