{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AVY3xAaJ-GWo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "from torchvision import transforms\n",
        "from torchvision import models\n",
        "from torchvision.datasets import CIFAR10\n",
        "\n",
        "from opacus import PrivacyEngine\n",
        "from opacus.validators import ModuleValidator\n",
        "\n",
        "from torchmetrics import Accuracy\n",
        "\n",
        "from transformers import BertConfig, BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "import zipfile\n",
        "import urllib.request\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\")\n",
        "\n",
        "STANFORD_SNLI_URL = \"https://nlp.stanford.edu/projects/snli/snli_1.0.zip\"\n",
        "DATA_DIR = \"data\"\n",
        "\n",
        "MAX_GRAD_NORM = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "5NinWQjbGYzR",
        "outputId": "714f0237-d20e-4d9b-d991-0053ff05c0d0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id                                       comment_text  toxic  \\\n",
              "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
              "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
              "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
              "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
              "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
              "\n",
              "   severe_toxic  obscene  threat  insult  identity_hate  \n",
              "0             0        0       0       0              0  \n",
              "1             0        0       0       0              0  \n",
              "2             0        0       0       0              0  \n",
              "3             0        0       0       0              0  \n",
              "4             0        0       0       0              0  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"toxic_comments.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((151592, 8), (7979, 8))"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, val_df = train_test_split(df, test_size=0.05)\n",
        "train_df.shape, val_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "LABEL_COLUMNS = df.columns.tolist()[2:]\n",
        "df[LABEL_COLUMNS].sum().sort_values().plot(kind=\"barh\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "train_toxic = train_df[train_df[LABEL_COLUMNS].sum(axis=1) > 0]\n",
        "train_clean = train_df[train_df[LABEL_COLUMNS].sum(axis=1) == 0]\n",
        "\n",
        "pd.DataFrame(dict(\n",
        "  toxic=[len(train_toxic)],\n",
        "  clean=[len(train_clean)]\n",
        ")).plot(kind='barh');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((30382, 8), (7979, 8))"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df = pd.concat([\n",
        "  train_toxic,\n",
        "  train_clean.sample(15_000)\n",
        "])\n",
        "\n",
        "train_df.shape, val_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>136533</th>\n",
              "      <td>da68c9213153ad77</td>\n",
              "      <td>Upset \\n\\nI TRUSTED YOU!! IT TOOK ME LIKE, 15 ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82504</th>\n",
              "      <td>dcb9537c47ee8ba7</td>\n",
              "      <td>\"\\n\\nLet's cut the bullshit, mmmkay?  You are ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78017</th>\n",
              "      <td>d0dd43e5382732fb</td>\n",
              "      <td>Hey \\n\\nHey guess what.  Not that I told anyon...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10406</th>\n",
              "      <td>1b7fe21f6b20f176</td>\n",
              "      <td>The Wack Pack \\n\\nYou're fucking insane and dr...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75486</th>\n",
              "      <td>c9ecb93f83a794ae</td>\n",
              "      <td>Hello, Anne. \\n\\nYou always were a bitch.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142853</th>\n",
              "      <td>fc013fd96a9408cb</td>\n",
              "      <td>Awesome! \\n\\nHi, \\n\\nJust wanted to state that...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17566</th>\n",
              "      <td>2e710f36659e2ac6</td>\n",
              "      <td>plus, you barely know anything about airliners...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>00280c0d0652b366</td>\n",
              "      <td>\"\\n\\n DH \\nDude, ABC officially says THIS is t...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142378</th>\n",
              "      <td>f9969dc36425e53a</td>\n",
              "      <td>\":::If you do a family tree starting with a th...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152064</th>\n",
              "      <td>875cf72423bf35db</td>\n",
              "      <td>between the two former realms</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30382 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      id                                       comment_text  \\\n",
              "136533  da68c9213153ad77  Upset \\n\\nI TRUSTED YOU!! IT TOOK ME LIKE, 15 ...   \n",
              "82504   dcb9537c47ee8ba7  \"\\n\\nLet's cut the bullshit, mmmkay?  You are ...   \n",
              "78017   d0dd43e5382732fb  Hey \\n\\nHey guess what.  Not that I told anyon...   \n",
              "10406   1b7fe21f6b20f176  The Wack Pack \\n\\nYou're fucking insane and dr...   \n",
              "75486   c9ecb93f83a794ae          Hello, Anne. \\n\\nYou always were a bitch.   \n",
              "...                  ...                                                ...   \n",
              "142853  fc013fd96a9408cb  Awesome! \\n\\nHi, \\n\\nJust wanted to state that...   \n",
              "17566   2e710f36659e2ac6  plus, you barely know anything about airliners...   \n",
              "64      00280c0d0652b366  \"\\n\\n DH \\nDude, ABC officially says THIS is t...   \n",
              "142378  f9969dc36425e53a  \":::If you do a family tree starting with a th...   \n",
              "152064  875cf72423bf35db                      between the two former realms   \n",
              "\n",
              "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
              "136533      1             0        0       0       0              0  \n",
              "82504       1             0        1       0       0              0  \n",
              "78017       1             0        1       0       0              0  \n",
              "10406       1             0        1       0       1              0  \n",
              "75486       1             0        1       0       1              0  \n",
              "...       ...           ...      ...     ...     ...            ...  \n",
              "142853      0             0        0       0       0              0  \n",
              "17566       0             0        0       0       0              0  \n",
              "64          0             0        0       0       0              0  \n",
              "142378      0             0        0       0       0              0  \n",
              "152064      0             0        0       0       0              0  \n",
              "\n",
              "[30382 rows x 8 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiWfzXMNG2YX",
        "outputId": "b8b50634-dcab-4abb-caa6-aa65d1f0c00e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model_name = \"bert-base-cased\"\n",
        "config = BertConfig.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=3,\n",
        ")\n",
        "tokenizer = BertTokenizer.from_pretrained(\n",
        "    \"bert-base-cased\",\n",
        "    do_lower_case=False,\n",
        ")\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-cased\",\n",
        "    config=config,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwRfnSwDJcZZ",
        "outputId": "2d4df1de-1822-4b74-e144-4b8f8eabac79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total parameters count: 108312579\n",
            "Trainable parameters count: 7680771\n"
          ]
        }
      ],
      "source": [
        "trainable_layers = [model.bert.encoder.layer[-1], model.bert.pooler, model.classifier]\n",
        "total_params = 0\n",
        "trainable_params = 0\n",
        "\n",
        "for p in model.parameters():\n",
        "        p.requires_grad = False\n",
        "        total_params += p.numel()\n",
        "\n",
        "for layer in trainable_layers:\n",
        "    for p in layer.parameters():\n",
        "        p.requires_grad = True\n",
        "        trainable_params += p.numel()\n",
        "\n",
        "print(f\"Total parameters count: {total_params}\") # ~108M\n",
        "print(f\"Trainable parameters count: {trainable_params}\") # ~7M"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLgyZ7DEJmV6"
      },
      "outputs": [],
      "source": [
        "LABEL_LIST = ['contradiction', 'entailment', 'neutral']\n",
        "MAX_SEQ_LENGHT = 128\n",
        "\n",
        "import torch\n",
        "import transformers\n",
        "from torch.utils.data import TensorDataset\n",
        "from transformers.data.processors.utils import InputExample\n",
        "from transformers.data.processors.glue import glue_convert_examples_to_features\n",
        "\n",
        "\n",
        "def _create_examples(df, set_type):\n",
        "    \"\"\" Convert raw dataframe to a list of InputExample. Filter malformed examples\n",
        "    \"\"\"\n",
        "    examples = []\n",
        "    for index, row in df.iterrows():\n",
        "        if row['gold_label'] not in LABEL_LIST:\n",
        "            continue\n",
        "        if not isinstance(row['sentence1'], str) or not isinstance(row['sentence2'], str):\n",
        "            continue\n",
        "            \n",
        "        guid = f\"{index}-{set_type}\"\n",
        "        examples.append(\n",
        "            InputExample(guid=guid, text_a=row['sentence1'], text_b=row['sentence2'], label=row['gold_label']))\n",
        "    return examples\n",
        "\n",
        "def _df_to_features(df, set_type):\n",
        "    \"\"\" Pre-process text. This method will:\n",
        "    1) tokenize inputs\n",
        "    2) cut or pad each sequence to MAX_SEQ_LENGHT\n",
        "    3) convert tokens into ids\n",
        "    \n",
        "    The output will contain:\n",
        "    `input_ids` - padded token ids sequence\n",
        "    `attention mask` - mask indicating padded tokens\n",
        "    `token_type_ids` - mask indicating the split between premise and hypothesis\n",
        "    `label` - label\n",
        "    \"\"\"\n",
        "    examples = _create_examples(df, set_type)\n",
        "    \n",
        "    #backward compatibility with older transformers versions\n",
        "    legacy_kwards = {}\n",
        "    from packaging import version\n",
        "    if version.parse(transformers.__version__) < version.parse(\"2.9.0\"):\n",
        "        legacy_kwards = {\n",
        "            \"pad_on_left\": False,\n",
        "            \"pad_token\": tokenizer.convert_tokens_to_ids([tokenizer.pad_token])[0],\n",
        "            \"pad_token_segment_id\": 0,\n",
        "        }\n",
        "    \n",
        "    return glue_convert_examples_to_features(\n",
        "        examples=examples,\n",
        "        tokenizer=tokenizer,\n",
        "        label_list=LABEL_LIST,\n",
        "        max_length=MAX_SEQ_LENGHT,\n",
        "        output_mode=\"classification\",\n",
        "        **legacy_kwards,\n",
        "    )\n",
        "\n",
        "def _features_to_dataset(features):\n",
        "    \"\"\" Convert features from `_df_to_features` into a single dataset\n",
        "    \"\"\"\n",
        "    all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
        "    all_attention_mask = torch.tensor(\n",
        "        [f.attention_mask for f in features], dtype=torch.long\n",
        "    )\n",
        "    all_token_type_ids = torch.tensor(\n",
        "        [f.token_type_ids for f in features], dtype=torch.long\n",
        "    )\n",
        "    all_labels = torch.tensor([f.label for f in features], dtype=torch.long)\n",
        "    dataset = TensorDataset(\n",
        "        all_input_ids, all_attention_mask, all_token_type_ids, all_labels\n",
        "    )\n",
        "\n",
        "    return dataset\n",
        "\n",
        "train_features = _df_to_features(df_train, \"train\")\n",
        "test_features = _df_to_features(df_test, \"test\")\n",
        "\n",
        "train_dataset = _features_to_dataset(train_features)\n",
        "test_dataset = _features_to_dataset(test_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6jirLDjPFa0"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32\n",
        "MAX_PHYSICAL_BATCH_SIZE = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KruInuy2Krmx"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from opacus.utils.uniform_sampler import UniformWithReplacementSampler\n",
        "\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
        "test_dataloader = DataLoader(test_dataset, sampler=SequentialSampler(test_dataset), batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXwFycfvPBmP"
      },
      "outputs": [],
      "source": [
        "# Move the model to appropriate device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Set the model to train mode (HuggingFace models load in eval mode)\n",
        "model = model.train()\n",
        "# Define optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, eps=1e-8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpXxkM8RPItQ"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 3\n",
        "LOGGING_INTERVAL = 5000 # once every how many steps we run evaluation cycle and report metrics\n",
        "EPSILON = 7.5\n",
        "DELTA = 1 / len(train_dataloader) # Parameter for privacy accounting. Probability of not achieving privacy guarantees"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZm7reB9PLV3"
      },
      "outputs": [],
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "def accuracy(preds, labels):\n",
        "    return (preds == labels).mean()\n",
        "\n",
        "# define evaluation cycle\n",
        "def evaluate(model):    \n",
        "    model.eval()\n",
        "\n",
        "    loss_arr = []\n",
        "    accuracy_arr = []\n",
        "    \n",
        "    for batch in test_dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            inputs = {'input_ids':      batch[0],\n",
        "                      'attention_mask': batch[1],\n",
        "                      'token_type_ids': batch[2],\n",
        "                      'labels':         batch[3]}\n",
        "\n",
        "            outputs = model(**inputs)\n",
        "            loss, logits = outputs[:2]\n",
        "            \n",
        "            preds = np.argmax(logits.detach().cpu().numpy(), axis=1)\n",
        "            labels = inputs['labels'].detach().cpu().numpy()\n",
        "            \n",
        "            loss_arr.append(loss.item())\n",
        "            accuracy_arr.append(accuracy(preds, labels))\n",
        "    \n",
        "    model.train()\n",
        "    return np.mean(loss_arr), np.mean(accuracy_arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3A3KE_9PSUi"
      },
      "outputs": [],
      "source": [
        "MAX_GRAD_NORM = 0.1\n",
        "\n",
        "privacy_engine = PrivacyEngine()\n",
        "\n",
        "model, optimizer, train_dataloader = privacy_engine.make_private_with_epsilon(\n",
        "    module=model,\n",
        "    optimizer=optimizer,\n",
        "    data_loader=train_dataloader,\n",
        "    target_delta=DELTA,\n",
        "    target_epsilon=EPSILON, \n",
        "    epochs=EPOCHS,\n",
        "    max_grad_norm=MAX_GRAD_NORM,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "ExJWjcd5Pjyb",
        "outputId": "70ea65db-a2e5-4c24-bf8e-6bbfb01e864d"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a80cb576140f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mopacus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_memory_manager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatchMemoryManager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'opacus'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from opacus.utils.batch_memory_manager import BatchMemoryManager\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    losses = []\n",
        "\n",
        "    with BatchMemoryManager(\n",
        "        data_loader=train_dataloader, \n",
        "        max_physical_batch_size=MAX_PHYSICAL_BATCH_SIZE, \n",
        "        optimizer=optimizer\n",
        "    ) as memory_safe_data_loader:\n",
        "        for step, batch in enumerate(tqdm(memory_safe_data_loader)):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            inputs = {'input_ids':      batch[0],\n",
        "                    'attention_mask': batch[1],\n",
        "                    'token_type_ids': batch[2],\n",
        "                    'labels':         batch[3]}\n",
        "\n",
        "            outputs = model(**inputs) # output = loss, logits, hidden_states, attentions\n",
        "\n",
        "            loss = outputs[0]\n",
        "            loss.backward()\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            if step > 0 and step % LOGGING_INTERVAL == 0:\n",
        "                train_loss = np.mean(losses)\n",
        "                eps = privacy_engine.get_epsilon(DELTA)\n",
        "\n",
        "                eval_loss, eval_accuracy = evaluate(model)\n",
        "\n",
        "                print(\n",
        "                  f\"Epoch: {epoch} | \"\n",
        "                  f\"Step: {step} | \"\n",
        "                  f\"Train loss: {train_loss:.3f} | \"\n",
        "                  f\"Eval loss: {eval_loss:.3f} | \"\n",
        "                  f\"Eval accuracy: {eval_accuracy:.3f} | \"\n",
        "                  f\"ɛ: {eps:.2f}\"\n",
        "                )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kaUWlZqOP0Nm"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
